<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CATALYST Lab</title>
    <link rel="stylesheet" href="css/pages.css">
</head>

<body>
    <!-- Header Navigation -->
    <header>
        <nav>
            <div class="site-title"><a href="index.html">CATALYST Lab</a></div>
            <button class="menu-toggle" onclick="toggleMenu()" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul>
                <li><a href="about.html">About</a></li>
                <li><a href="research.html" class="active">Research</a></li>
                <li><a href="group.html">Group</a></li>
                <li><a href="information_for_prospective_students.html">Prospective Students</a></li>
                <li><a href="code.html">Code</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </nav>
    </header>

    <main class="page-content">
        <h2>Research</h2>
        <p class="research-intro">Our research spans the intersection of artificial intelligence, complex systems, and
            computational methods. We develop novel approaches to understanding and engineering intelligent multi-agent
            systems.</p>
        <!-- Theory of Mind Research -->
        <div class="research-theme">
            <div class="research-theme-content">
                <div class="research-theme-image">
                    <img src="assets/images/research/tom.png" alt="Theory of Mind Research">
                </div>
                <div class="research-theme-text">
                    <h3>LLM Strategizing and Theory of Mind</h3>
                    <p>how do LLMs think, strategize & plan? How do their interactions differ when they interact with
                        humans vs with one another?"</p>
                    <div class="research-details">
                        <p>Large language models demonstrate impressive zero-shot reasoning abilities, but struggle
                            significantly with long-term strategic reasoning in single or multiagent settings. Recent
                            work shows that when placed in competitive, cooperative, or mixed-motive environments, LLMs
                            exhibit nontrivial emergent strategic behavior.</p>
                        <p>In today's world, so dominated by either human LLM engagement or multi-LLM interaction,
                            understanding and making such long-term reasoning robust is key to society. We combine tools
                            from computational Game Theory, Large Language Models, finetuning, and training with
                            concepts from cognitive social science to develop in depth understanding of such systems
                            such things </p>
                        <p><strong>Selected Publications & Challenges:</strong></p>
                        <ul>
                            <li><a href="https://dl.acm.org/doi/abs/10.5555/3635637.3663018" target="_blank">Game of
                                    thoughts: Iterative reasoning in game-theoretic domains with large language
                                    models</a><br>
                                B Kempinski, I Gemp, K Larson, M Lanctot, Y Bachrach, T Kachman<br>
                                <em>International Foundation for Autonomous Agents and Multiagent Systems</em>
                            </li>
                            <li><a href="https://github.com/google-deepmind/theory_of_mind"
                                    target="_blank">Theory-of-Mind Challenges for LLM Agents</a><br>
                                Push the boundaries of AI social intelligence through persuasion, trust, and strategic
                                cooperation across four mind-bending challenges.</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Chemical AI Research -->
        <div class="research-theme">
            <div class="research-theme-content">
                <div class="research-theme-image">
                    <img src="assets/images/research/ChemAI.png" alt="Chemical AI Research">
                </div>
                <div class="research-theme-text">
                    <h3>Chemical Artificial Intelligence</h3>
                    <p>How can AI systems advance our understanding of the natural sciences, and how can we learn from
                        automation to autonomisation? Advancing how we conduct scientific discovery, both theoretically
                        and experimentally, can have a profound impact on our society.</p>
                    <div class="research-details">
                        <p>Within the Big Chemistry consortium, we tackle groundbreaking scientific problems by
                            utilizing a combination of Deep Learning methods, Foundation models, molecular and dynamical
                            simulations, with high-throughput experimental data </p>
                        <p><strong>Selected Publications:</strong></p>
                        <ul>
                            <li><a href="https://pubs.acs.org/doi/10.1021/acs.jcim.4c00975" target="_blank">Modeling
                                    chemical reaction networks using neural ordinary differential equations</a><br>
                                ACM Thöni, WE Robinson, Y Bachrach, WTS Huck, T Kachman<br>
                                <em>Journal of Chemical Information and Modeling 65 (9), 4346-4352</em>
                            </li>
                            <li><a href="https://pubs.rsc.org/en/content/articlelanding/2024/dd/d4dd00101j"
                                    target="_blank">What can attribution methods show us about chemical language
                                    models?</a><br>
                                S Hödl, T Kachman, Y Bachrach, WTS Huck, WE Robinson<br>
                                <em>Digital Discovery 3 (9), 1738-1748</em>
                            </li>
                            <li><a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.119.038001"
                                    target="_blank">Self-organized resonance during search of a diverse chemical
                                    space</a><br>
                                T Kachman, JA Owen, JL England<br>
                                <em>Physical Review Letters 119 (3), 038001</em>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Mean Field Games Research -->
        <div class="research-theme research-theme-reverse">
            <div class="research-theme-content">
                <div class="research-theme-text">
                    <h3>Game Theory & Deep Learning</h3>
                    <p>How can Deep learning help us understand game-theoretical scenarios for unseen and generalized
                        games?</p>
                    <div class="research-details">
                        <p>Understanding players' value attribution, such as Shapley value or bandit indexes, in games
                            is fundamental; it can help us shape coalitions, influence decision-making, and plan our
                            strategy effectively. However, calculating such indexes is computationally intensive to the
                            point of being intractable. Understanding game-theoretical scenarios using tools from AI is
                            a key
                            theme of our group.</p>
                        <p><strong>Selected Publications:</strong></p>
                        <ul>
                            <li><a href="https://arxiv.org/abs/2504.13228" target="_blank">Modelling Mean-Field Games
                                    with Neural Ordinary Differential Equations</a><br>
                                A Thöni, Y Bachrach, T Kachman<br>
                                <em>arXiv preprint arXiv:2504.13228</em>
                            </li>
                            <li><a href="https://link.springer.com/chapter/10.1007/978-3-031-66336-9_1"
                                    target="_blank">InfluenceNet: AI Models for Banzhaf and Shapley Value
                                    Prediction</a><br>
                                B Kempinski, T Kachman<br>
                                <em>Intelligent Systems Conference, 1-23</em>
                            </li>
                            <li><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/a2b0c23047ffa664b583e8be9e5b34f7-Abstract-Conference.html"
                                    target="_blank">Neural payoff machines: Predicting fair and stable payoff
                                    allocations among team members</a><br>
                                D Cornelisse, T Rood, Y Bachrach, M Malinowski, T Kachman<br>
                                <em>Advances in Neural Information Processing Systems 35, 25491-25503</em>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="research-theme-image">
                    <img src="assets/images/research/MFGindex.png" alt="Mean Field Games Research">
                </div>
            </div>
        </div>


        <!-- Training Dynamics Research -->
        <div class="research-theme research-theme-reverse">
            <div class="research-theme-content">
                <div class="research-theme-text">
                    <h3>Dynamical Aspects of Learning in Neural Networks</h3>
                    <p>What can the underlying dynamical process of training neural networks teach us about the final
                        state of it and its learning capacity?</p>
                    <div class="research-details">
                        <p>Understanding how neural networks learn from data and what the underlying dynamical processes
                            is is key to fundamental aspects of our theoretical understanding of artificial neural
                            networks. Using deep mathematical tooling from dynamical systems, combinatorial
                            optimization, and at-scale deep learning systems, this insight is key to our group's
                            research.</p>
                        <p><strong>Selected Publications:</strong></p>
                        <ul>
                            <li><a href="https://arxiv.org/abs/2111.05803" target="_blank">Gradients are Not All You
                                    Need</a><br>
                                Jonathan Lorraine, Jack Parker-Holder, Paul Vicol, Aldo Pacchiano, Luke Metz, Tal
                                Kachman, Jakob Foerster<br>
                                <em>arXiv preprint arXiv:2111.05803, 2022</em>
                            </li>
                            <li><a href="https://arxiv.org/abs/2112.14570" target="_blank">Lyapunov exponents for
                                    diversity in differentiable games</a><br>
                                J Lorraine, P Vicol, J Parker-Holder, T Kachman<br>
                                <em>arXiv preprint arXiv:2112.14570</em>
                            </li>
                            <li><a href="https://drive.google.com/file/d/1hLCRSj8DSeruIiXJm7lqJPDGJNfQRGDm/view"
                                    target="_blank">Using bifurcations for diversity in differentiable games</a><br>
                                Jonathan Lorraine, Jack Parker-Holder, Paul Vicol, Aldo Pacchiano, Luke Metz, Tal
                                Kachman, Jakob Foerster<br>
                                <em>ICML 2021 Beyond First Order Methods Workshop</em>
                            </li>
                        </ul>
                    </div>
                </div>
                <div class="research-theme-image">
                    <img src="assets/images/research/traindynamics.png" alt="Training Dynamics Research">
                </div>
            </div>
        </div>

    </main>

    <footer>
        <p>© 2025 CATALYST Lab. All rights reserved.</p>
    </footer>
    <script src="js/main.js"></script>
</body>

</html>
